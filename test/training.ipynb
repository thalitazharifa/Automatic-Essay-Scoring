{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses pre-processing selesai, file telah disimpan sebagai 'pre_processing_data.csv'\n"
     ]
    }
   ],
   "source": [
    "#step 1 preprocessing data\n",
    "\n",
    "# Import library\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca dataset dari file .tsv\n",
    "raw_data = pd.read_csv(r'E:\\Kuliah\\Tugas Akhir\\AES\\code\\AES\\data\\asap-aes\\training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "# Menyaring data untuk hanya mengambil essay_set dengan nilai 7\n",
    "filtered_dataset = raw_data[raw_data['essay_set'] == 7].copy()\n",
    "\n",
    "# Menyimpan dataset yang telah disaring ke dalam file CSV\n",
    "filtered_dataset.to_csv('aes_dataset_value_7.csv', index=False)\n",
    "\n",
    "# Menentukan kolom yang akan digabungkan untuk skor Struktur\n",
    "skor_struktur = ['rater1_trait1', 'rater1_trait2', 'rater1_trait3', 'rater2_trait1', 'rater2_trait2', 'rater2_trait3']\n",
    "\n",
    "# Menghitung skor struktur sebagai rata-rata dari 6 karakteristik yang ada\n",
    "filtered_dataset.loc[:, 'skor_struktur'] = filtered_dataset[skor_struktur].sum(axis=1) / len(skor_struktur)\n",
    "\n",
    "# Menentukan kolom yang akan digabungkan untuk skor Tata Bahasa\n",
    "skor_tata_bahasa = ['rater1_trait4', 'rater2_trait4']\n",
    "\n",
    "# Menghitung skor tata bahasa sebagai rata-rata dari 2 karakteristik yang ada\n",
    "filtered_dataset.loc[:, 'skor_tata_bahasa'] = filtered_dataset[skor_tata_bahasa].sum(axis=1) / len(skor_tata_bahasa)\n",
    "\n",
    "# Normalisasi skor Struktur dalam rentang 0-10\n",
    "min_value_struktur = filtered_dataset['skor_struktur'].min()\n",
    "max_value_struktur = filtered_dataset['skor_struktur'].max()\n",
    "filtered_dataset['skor_struktur_normalized'] = 10 * (filtered_dataset['skor_struktur'] - min_value_struktur) / (max_value_struktur - min_value_struktur)\n",
    "filtered_dataset['skor_struktur_normalized'] = filtered_dataset['skor_struktur_normalized'].round(1)\n",
    "\n",
    "# Normalisasi skor Tata Bahasa dalam rentang 0-10\n",
    "min_value_tata_bahasa = filtered_dataset['skor_tata_bahasa'].min()\n",
    "max_value_tata_bahasa = filtered_dataset['skor_tata_bahasa'].max()\n",
    "filtered_dataset['skor_tata_bahasa_normalized'] = 10 * (filtered_dataset['skor_tata_bahasa'] - min_value_tata_bahasa) / (max_value_tata_bahasa - min_value_tata_bahasa)\n",
    "filtered_dataset['skor_tata_bahasa_normalized'] = filtered_dataset['skor_tata_bahasa_normalized'].round(1)\n",
    "\n",
    "# Pilih kolom-kolom yang relevan untuk disimpan dalam dataset hasil pre-processing\n",
    "pre_processing_data = ['essay_id', 'essay_set', 'essay', 'skor_struktur_normalized', 'skor_tata_bahasa_normalized']\n",
    "\n",
    "# Membuat dataset akhir yang berisi data yang sudah diproses\n",
    "final_pre_processing_data = filtered_dataset[pre_processing_data]\n",
    "\n",
    "# Menyimpan data hasil pre-processing ke dalam file CSV\n",
    "final_pre_processing_data.to_csv('pre_processing_data.csv', index=False)\n",
    "\n",
    "print(\"Proses pre-processing selesai, file telah disimpan sebagai 'pre_processing_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n",
      "11.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Should show the version (e.g., 2.0.1+cu118 for CUDA 11.8)\n",
    "print(torch.version.cuda)  # Should show the CUDA version PyTorch was built with\n",
    "print(torch.backends.cudnn.enabled)  # Should be True for CUDA-enabled builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "tensor([[0.6529, 0.7529, 0.6967],\n",
      "        [0.1476, 0.3936, 0.8420],\n",
      "        [0.7451, 0.4444, 0.2912]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Test if CUDA is available and the model is using the GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Example tensor operation on GPU\n",
    "tensor = torch.rand(3, 3).to(device)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.8575, Training QWK Score: -0.0202\n",
      "Validation Loss: 5.3523, Validation QWK Score: 0.0042\n",
      "Epoch [2/5], Loss: 0.1244, Training QWK Score: 0.0403\n",
      "Validation Loss: 4.5689, Validation QWK Score: 0.2391\n",
      "Epoch [3/5], Loss: 0.1889, Training QWK Score: -0.0004\n",
      "Validation Loss: 4.2990, Validation QWK Score: 0.2672\n",
      "Epoch [4/5], Loss: 1.4143, Training QWK Score: -0.0119\n",
      "Validation Loss: 4.2090, Validation QWK Score: 0.2416\n",
      "Epoch [5/5], Loss: 0.4794, Training QWK Score: 0.0333\n",
      "Validation Loss: 4.1540, Validation QWK Score: 0.4881\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Load preprocessed dataset\n",
    "data_preprocessing = pd.read_csv('pre_processing_data.csv')\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Move BERT model to the device (CUDA or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Extract essay texts\n",
    "essay_texts = data_preprocessing['essay'].tolist()\n",
    "\n",
    "# Tokenize essays with padding and truncation\n",
    "inputs = tokenizer(essay_texts, return_tensors='pt', padding=True, max_length=512, truncation=True)\n",
    "\n",
    "# Extract token IDs and attention mask\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Move tokenized inputs to the device\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "\n",
    "# Define the Structure Scoring Model (LSTM + Dropout + Dense)\n",
    "class StructureScoreModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768):  # Input size (BERT hidden size)\n",
    "        super(StructureScoreModel, self).__init__()\n",
    "        # LSTM Layer 1 with 400 hidden units (Bidirectional, so output size will be 800)\n",
    "        self.lstm1 = nn.LSTM(input_size=hidden_size, hidden_size=400, batch_first=True, bidirectional=True)\n",
    "        # LSTM Layer 2 with 128 hidden units (Bidirectional, so output size will be 256)\n",
    "        self.lstm2 = nn.LSTM(input_size=800, hidden_size=128, batch_first=True, bidirectional=True)\n",
    "        # Dropout Layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # Dense Layer with ReLU activation to output a single score\n",
    "        # The input to the dense layer will have size 256 (output from second LSTM, bidirectional)\n",
    "        self.dense = nn.Linear(128 * 2, 1)  # Output layer for the score (128 * 2 for bidirectional)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through first LSTM layer\n",
    "        x, _ = self.lstm1(x)  # Output size will be (batch_size, seq_len, 800) due to bidirectional LSTM\n",
    "        # Pass through second LSTM layer\n",
    "        x, _ = self.lstm2(x)  # Output size will be (batch_size, seq_len, 256) due to bidirectional LSTM\n",
    "        # Apply dropout to the output of the second LSTM\n",
    "        x = self.dropout(x)\n",
    "        # Take the output from the last sequence token (seq_length - 1)\n",
    "        x = x[:, -1, :]  # Select the last token (from sequence length)\n",
    "        # Apply dense layer and ReLU activation\n",
    "        x = self.dense(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model and move to device\n",
    "model_structure = StructureScoreModel(hidden_size=768).to(device)\n",
    "\n",
    "# Prepare structure scores for training\n",
    "structure_scores = torch.tensor(data_preprocessing['skor_struktur_normalized'].values, dtype=torch.float).to(device)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_input_ids, val_input_ids, train_attention_mask, val_attention_mask, train_scores, val_scores = train_test_split(\n",
    "    input_ids.cpu(), attention_mask.cpu(), structure_scores.cpu(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TensorDataset and DataLoader for batching\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_scores)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_mask, val_scores)\n",
    "batch_size = 2\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression task\n",
    "optimizer = torch.optim.Adam(model_structure.parameters(), lr=1e-5)\n",
    "\n",
    "# Function to discretize continuous scores into categories\n",
    "def discretize_scores(scores, bins=10):\n",
    "    min_score = np.min(scores)\n",
    "    max_score = np.max(scores)\n",
    "    bin_edges = np.linspace(min_score, max_score, bins + 1)\n",
    "    discretized_scores = np.digitize(scores, bin_edges) - 1  # Subtract 1 to make categories 0-indexed\n",
    "    return discretized_scores\n",
    "\n",
    "# Function to scale the scores to a range of 1-10\n",
    "def scale_scores_to_1_10(scores):\n",
    "    min_score = np.min(scores)\n",
    "    max_score = np.max(scores)\n",
    "    scaled_scores = 1 + 9 * (scores - min_score) / (max_score - min_score)\n",
    "    return scaled_scores\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_structure.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    predicted_structure_scores_train = []\n",
    "    true_structure_scores_train = []\n",
    "    for batch in train_dataloader:\n",
    "        input_ids_batch, attention_mask_batch, structure_scores_batch = batch\n",
    "        input_ids_batch = input_ids_batch.to(device)\n",
    "        attention_mask_batch = attention_mask_batch.to(device)\n",
    "        structure_scores_batch = structure_scores_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids_batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "        bert_embeddings = outputs.last_hidden_state\n",
    "        predictions = model_structure(bert_embeddings)\n",
    "\n",
    "        loss = criterion(predictions.squeeze(), structure_scores_batch.squeeze())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store predictions and true values for QWK calculation\n",
    "        predicted_structure_scores_train.extend(predictions.detach().cpu().numpy().flatten())  # Detach here\n",
    "        true_structure_scores_train.extend(structure_scores_batch.detach().cpu().numpy())  # Detach here\n",
    "\n",
    "    # Calculate QWK for training\n",
    "    predicted_structure_scores_train_scaled = scale_scores_to_1_10(predicted_structure_scores_train)\n",
    "    true_structure_scores_train_scaled = scale_scores_to_1_10(true_structure_scores_train)\n",
    "\n",
    "    qwk_train_score = cohen_kappa_score(discretize_scores(predicted_structure_scores_train_scaled),\n",
    "                                        discretize_scores(true_structure_scores_train_scaled), weights='quadratic')\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Training QWK Score: {qwk_train_score:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model_structure.eval()\n",
    "    predicted_structure_scores_val = []\n",
    "    true_structure_scores_val = []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids_batch, attention_mask_batch, structure_scores_batch = batch\n",
    "            input_ids_batch = input_ids_batch.to(device)\n",
    "            attention_mask_batch = attention_mask_batch.to(device)\n",
    "            structure_scores_batch = structure_scores_batch.to(device)\n",
    "\n",
    "            outputs = model(input_ids_batch, attention_mask=attention_mask_batch)\n",
    "            bert_embeddings = outputs.last_hidden_state\n",
    "\n",
    "            predictions = model_structure(bert_embeddings)\n",
    "\n",
    "            val_loss += criterion(predictions.squeeze(), structure_scores_batch.squeeze()).item()\n",
    "\n",
    "            # Store predictions and true values for QWK calculation\n",
    "            predicted_structure_scores_val.extend(predictions.detach().cpu().numpy().flatten())  # Detach here\n",
    "            true_structure_scores_val.extend(structure_scores_batch.detach().cpu().numpy())  # Detach here\n",
    "\n",
    "    val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "    # Scale predictions to range 1-10 for validation\n",
    "    predicted_structure_scores_val_scaled = scale_scores_to_1_10(predicted_structure_scores_val)\n",
    "    true_structure_scores_val_scaled = scale_scores_to_1_10(true_structure_scores_val)\n",
    "\n",
    "    # Calculate QWK for validation\n",
    "    qwk_val_score = cohen_kappa_score(discretize_scores(predicted_structure_scores_val_scaled),\n",
    "                                    discretize_scores(true_structure_scores_val_scaled), weights='quadratic')\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation QWK Score: {qwk_val_score:.4f}\")\n",
    "\n",
    "\n",
    "# Save both raw and scaled predictions to CSV\n",
    "predictions_combined_df = pd.DataFrame({\n",
    "    'true_scores_raw': true_structure_scores_val,                # Actual scores (raw)\n",
    "    'predicted_scores_raw': predicted_structure_scores_val,  # Predicted scores (raw)\n",
    "    'true_scores_scaled': true_structure_scores_val_scaled,  # Actual scores (scaled)\n",
    "    'predicted_scores_scaled': predicted_structure_scores_val_scaled  # Predicted scores (scaled)\n",
    "})\n",
    "predictions_combined_df.to_csv('predicted_structure_scores_combined.csv', index=False)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
